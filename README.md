â­ Gregory Livingston â€“ Applied AI Portfolio

Welcome to my Applied Artificial Intelligence Portfolio, a collection of my work from the Applied AI & Robotics Program at Houston Community College.
This portfolio highlights my progress, skills, and projects in computer vision, machine learning, and intelligent systems development.
___

ğŸ‘¤ About Me

My name is Gregory Livingston, and I am pursuing an A.A.S. in Artificial Intelligence and Robotics.
I am passionate about designing intelligent robotic systems that operate across land, sea, and air to help people in real-world environments.

My interests include:

ğŸ¥ Surgical and medical robotics

âœˆï¸ Aerospace and autonomous flight systems

ğŸ›¡ï¸ Defense, safety, and mission-critical robotics

I am also preparing for a B.S. in Mechanical Engineering Technology (Mechatronics) to combine AI with engineering and hardware integration.
___


ğŸ§  Technical Skills
Artificial Intelligence & Computer Vision

Image processing and pixel-level transformations

Classical ML for image classification

Neural Networks & Convolutional Neural Networks (CNNs)

Transfer Learning

Visionâ€“Language Models (VLMs)

Image captioning systems

AI pipeline design and model evaluation

Programming & Tools

Python (NumPy, Pandas, Matplotlib)

Jupyter Notebook & Google Colab

Hugging Face Transformers

Git & GitHub

Prompt Engineering

ğŸ› ï¸ Tools & Platforms

ğŸ Python

ğŸ““ Jupyter Notebook / Google Colab

ğŸ¤— Hugging Face Model Hub

ğŸ™ GitHub for version control

ğŸ–¼ Image datasets and testing utilities


ğŸ“˜ Featured Course & Project
Computer Vision â€“ ITAI 1378
___

This course covered:

Image processing fundamentals

Machine learning for computer vision

Convolutional Neural Networks

Object detection workflows

Visionâ€“Language Models and image captioning

â­ Final Project â€“ VisionTalk: Image Captioning System

ğŸ“ Project Folder:
ComputerVision-ITAI1378/VisionTalk-Image-Captioning
***

VisionTalk is an AI system that generates natural-language captions from images using a pre-trained BLIP Visionâ€“Language Model.

The project demonstrates:

Image preprocessing

Transformer-based inference

Connecting visual input to text generation

A complete, reproducible AI pipeline

ğŸ—‚ï¸ Repository Structure
Gregory-Livingston-Applied-AI-Portfolio/
â”œâ”€â”€ README.md                      # This file (portfolio overview)
â””â”€â”€ ComputerVision-ITAI1378/
    â”œâ”€â”€ README.md                  # Course summary
    â””â”€â”€ VisionTalk-Image-Captioning/
        â”œâ”€â”€ README.md              # Project documentation
        â”œâ”€â”€ VisionTalk_Image_Captioning.ipynb
        â””â”€â”€ results/               # Output screenshots & examples

# ğŸ” How to Navigate This Portfolio


1. **Start with the course overview**  
   ğŸ“ `ComputerVision-ITAI1378/`

2. **Open the final image captioning project**  
   ğŸ“ `ComputerVision-ITAI1378/VisionTalk-Image-Captioning/`

3. **Explore the results folder**  
   ğŸ“ `results/`  
   This contains screenshots and example captions generated by the model.

4. **Open and review the notebook**  
   Run the `.ipynb` file to see the code, explanations, and caption-generation process.

Review code, explanations, and sample inference inside the .ipynb file.



ğŸ“¬ Contact

If you'd like to connect or learn more:

ğŸ“§ Email: w216359933@student.hccs.edu

ğŸ”— LinkedIn: https://www.linkedin.com/in/greglivin

ğŸ™ GitHub: https://github.com/GregLivin

Thank you for reviewing my Applied AI portfolio!
